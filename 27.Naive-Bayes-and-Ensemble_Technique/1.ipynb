{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Questions: Na√Øve Bayes-1\n",
    "\n",
    "## Q1. What is Bayes' theorem?\n",
    "Bayes' theorem is a fundamental theorem in probability theory that provides a way to update the probability of a hypothesis based on new evidence. It relates conditional probabilities and allows us to calculate the probability of an event, given prior knowledge of conditions that might be related to the event.\n",
    "\n",
    "---\n",
    "\n",
    "## Q2. What is the formula for Bayes' theorem?\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "\\[\n",
    "P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the posterior probability (the probability of event A given B),\n",
    "- \\( P(B|A) \\) is the likelihood (the probability of event B given A),\n",
    "- \\( P(A) \\) is the prior probability (the initial probability of event A),\n",
    "- \\( P(B) \\) is the marginal likelihood (the total probability of event B).\n",
    "\n",
    "---\n",
    "\n",
    "## Q3. How is Bayes' theorem used in practice?\n",
    "Bayes' theorem is used in a wide range of applications such as spam filtering, medical diagnosis, and machine learning. In practice, it helps in decision-making and classification problems by updating the probability estimates of hypotheses as new evidence is observed.\n",
    "\n",
    "For example, in spam filtering, Bayes' theorem can be used to determine the probability that an email is spam based on the presence or absence of certain words in the email.\n",
    "\n",
    "---\n",
    "\n",
    "## Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "Bayes' theorem is derived from the definition of conditional probability. It uses conditional probability to reverse the conditioning, allowing us to compute the probability of a cause given an observed effect. Essentially, it provides a way to update the probability of a hypothesis based on observed evidence, making it a powerful tool in probabilistic reasoning.\n",
    "\n",
    "---\n",
    "\n",
    "## Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "There are three main types of Naive Bayes classifiers:\n",
    "1. **Gaussian Naive Bayes**: Used when the features are continuous and assumed to follow a normal (Gaussian) distribution.\n",
    "2. **Multinomial Naive Bayes**: Suitable for discrete data, commonly used for document classification problems where word counts are the features.\n",
    "3. **Bernoulli Naive Bayes**: Best for binary/boolean features, where each feature represents the presence or absence of a particular attribute.\n",
    "\n",
    "The choice of classifier depends on the nature of the features in the dataset. If the features are continuous, Gaussian Naive Bayes is often used. For text classification, Multinomial Naive Bayes is typically preferred.\n",
    "\n",
    "---\n",
    "\n",
    "## Q6. Naive Bayes Classification Problem:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features \\( X_1 = 3 \\) and \\( X_2 = 4 \\). The following table shows the frequency of each feature value for each class:\n",
    "\n",
    "| Class | X1 = 1 | X1 = 2 | X1 = 3 | X2 = 1 | X2 = 2 | X2 = 3 | X2 = 4 |\n",
    "|-------|--------|--------|--------|--------|--------|--------|--------|\n",
    "| A     |   3    |   3    |   4    |   4    |   3    |   3    |   3    |\n",
    "| B     |   2    |   2    |   1    |   2    |   2    |   2    |   3    |\n",
    "\n",
    "Assuming equal prior probabilities for each class, the Naive Bayes classifier would predict the class for the new instance with \\( X_1 = 3 \\) and \\( X_2 = 4 \\).\n",
    "\n",
    "### Solution:\n",
    "\n",
    "- **P(A)** = **P(B)** = 0.5 (since prior probabilities are equal).\n",
    "- Calculate the likelihood for each class:\n",
    "  \n",
    "  - For Class A:\n",
    "    \\[\n",
    "    P(X_1 = 3 | A) = \\frac{4}{(3+3+4)} = \\frac{4}{10}, \\quad P(X_2 = 4 | A) = \\frac{3}{(4+3+3+3)} = \\frac{3}{13}\n",
    "    \\]\n",
    "    So, the probability for Class A is:\n",
    "    \\[\n",
    "    P(A | X_1 = 3, X_2 = 4) = 0.5 \\times \\frac{4}{10} \\times \\frac{3}{13}\n",
    "    \\]\n",
    "  \n",
    "  - For Class B:\n",
    "    \\[\n",
    "    P(X_1 = 3 | B) = \\frac{1}{(2+2+1)} = \\frac{1}{5}, \\quad P(X_2 = 4 | B) = \\frac{3}{(2+2+2+3)} = \\frac{3}{9}\n",
    "    \\]\n",
    "    So, the probability for Class B is:\n",
    "    \\[\n",
    "    P(B | X_1 = 3, X_2 = 4) = 0.5 \\times \\frac{1}{5} \\times \\frac{3}{9}\n",
    "    \\]\n",
    "  \n",
    "- Compare the two probabilities and choose the class with the higher value.\n",
    "\n",
    "This will give the predicted class for the new instance.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
