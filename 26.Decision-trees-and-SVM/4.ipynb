{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment Questions: Support Vector Machines-2\n",
    "### Q1. What is the relationship between polynomial functions and kernel functions in machine learning algorithms?\n",
    "\n",
    "In machine learning, kernel functions are used to transform the data into a higher-dimensional space, where it becomes easier to perform tasks such as classification or regression. A **polynomial kernel** is a type of kernel function that allows Support Vector Machines (SVM) to operate in a higher-dimensional feature space using a polynomial function.\n",
    "\n",
    "The relationship between **polynomial functions** and **kernel functions** is that a polynomial kernel is a specific type of kernel function that can be expressed as:\n",
    "  \n",
    "\\[\n",
    "K(x, y) = (x^T y + c)^d\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( x^T y \\) represents the dot product between two feature vectors.\n",
    "- \\( c \\) is a free parameter that trades off the influence of higher-order vs. lower-order terms.\n",
    "- \\( d \\) is the degree of the polynomial.\n",
    "\n",
    "The polynomial kernel allows SVMs to learn non-linear decision boundaries by implicitly mapping the input data into a higher-dimensional polynomial feature space without explicitly computing the transformation.\n",
    "\n",
    "---\n",
    "\n",
    "### Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\n",
    "\n",
    "To implement an SVM with a **polynomial kernel** in Python using Scikit-learn, follow the steps below:\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load a dataset\n",
    "data = datasets.load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create an SVM classifier with a polynomial kernel\n",
    "svm_classifier = SVC(kernel='poly', degree=3, C=1.0)\n",
    "\n",
    "# Train the model\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels on the test set\n",
    "y_pred = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "```\n",
    "\n",
    "This script uses the **Scikit-learn** library to create an SVM classifier with a polynomial kernel. The degree of the polynomial is set to 3, but it can be adjusted based on the specific problem.\n",
    "\n",
    "---\n",
    "\n",
    "### Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\n",
    "\n",
    "In **Support Vector Regression (SVR)**, the epsilon (\\(\\epsilon\\)) parameter defines a margin of tolerance within which no penalty is given for errors. Increasing the value of epsilon increases the width of the margin.\n",
    "\n",
    "- As \\(\\epsilon\\) increases, the **number of support vectors decreases**, because a wider margin means that more data points are allowed to lie within the margin without affecting the model.\n",
    "- Conversely, reducing \\(\\epsilon\\) results in more support vectors, as more data points will lie outside the narrower margin.\n",
    "\n",
    "Therefore, increasing \\(\\epsilon\\) typically simplifies the model and makes it less sensitive to small variations in the data, while decreasing \\(\\epsilon\\) makes the model more sensitive.\n",
    "\n",
    "---\n",
    "\n",
    "### Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works and provide examples of when you might want to increase or decrease its value?\n",
    "\n",
    "1. **Kernel Function**:\n",
    "   - The kernel function defines the transformation of the input data into a higher-dimensional space. Common kernel functions include linear, polynomial, and RBF (Radial Basis Function).\n",
    "   - **Example**: If your data is linearly separable, you can use the linear kernel; if it is not, you can use polynomial or RBF kernels.\n",
    "\n",
    "2. **C Parameter**:\n",
    "   - The **C parameter** controls the trade-off between maximizing the margin and minimizing the classification error.\n",
    "   - **Example**: Increasing \\(C\\) makes the model focus more on correctly classifying all data points, possibly at the cost of a smaller margin. Decreasing \\(C\\) allows a larger margin but tolerates more misclassifications.\n",
    "\n",
    "3. **Epsilon (\\(\\epsilon\\)) Parameter**:\n",
    "   - The epsilon parameter defines the width of the margin in SVR. It specifies the tolerance within which errors are ignored.\n",
    "   - **Example**: A larger \\(\\epsilon\\) can be used when small deviations from the true values are acceptable.\n",
    "\n",
    "4. **Gamma Parameter**:\n",
    "   - The **gamma parameter** defines the influence of individual training samples. High gamma values make the decision boundary focus on a few points, while lower values make it smoother.\n",
    "   - **Example**: Increasing gamma makes the model more sensitive to individual data points, while decreasing it makes the decision boundary more general.\n",
    "\n",
    "The choice of these parameters depends on the specific problem and dataset. For example, you might want to increase \\(C\\) and gamma in cases where you want a highly accurate model, but this may lead to overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "### Q5. Assignment\n",
    "\n",
    "Here is a general outline of the steps to complete the assignment:\n",
    "\n",
    "1. **Import the necessary libraries and load the dataset**:\n",
    "   ```python\n",
    "   import pandas as pd\n",
    "   from sklearn.model_selection import train_test_split\n",
    "   from sklearn.preprocessing import StandardScaler\n",
    "   from sklearn.svm import SVC\n",
    "   from sklearn.metrics import classification_report\n",
    "   from sklearn.model_selection import GridSearchCV\n",
    "   ```\n",
    "\n",
    "2. **Split the dataset into training and testing sets**:\n",
    "   ```python\n",
    "   # Assuming `df` is your dataset\n",
    "   X = df.drop('target_column', axis=1)\n",
    "   y = df['target_column']\n",
    "   X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "   ```\n",
    "\n",
    "3. **Preprocess the data (e.g., scaling)**:\n",
    "   ```python\n",
    "   scaler = StandardScaler()\n",
    "   X_train = scaler.fit_transform(X_train)\n",
    "   X_test = scaler.transform(X_test)\n",
    "   ```\n",
    "\n",
    "4. **Create and train the SVC classifier**:\n",
    "   ```python\n",
    "   svc = SVC()\n",
    "   svc.fit(X_train, y_train)\n",
    "   ```\n",
    "\n",
    "5. **Predict labels on the testing set**:\n",
    "   ```python\n",
    "   y_pred = svc.predict(X_test)\n",
    "   ```\n",
    "\n",
    "6. **Evaluate the performance**:\n",
    "   ```python\n",
    "   print(classification_report(y_test, y_pred))\n",
    "   ```\n",
    "\n",
    "7. **Tune hyperparameters using GridSearchCV**:\n",
    "   ```python\n",
    "   param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf', 'poly']}\n",
    "   grid_search = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "   grid_search.fit(X_train, y_train)\n",
    "   ```\n",
    "\n",
    "8. **Save the trained classifier**:\n",
    "   ```python\n",
    "   import joblib\n",
    "   joblib.dump(grid_search.best_estimator_, 'svc_model.pkl')\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
