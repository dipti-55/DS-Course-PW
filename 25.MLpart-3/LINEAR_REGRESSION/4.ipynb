{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment: Regression-4\n",
    "\n",
    "## Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\n",
    "Lasso Regression, or **Least Absolute Shrinkage and Selection Operator**, is a type of linear regression that includes L1 regularization. In Lasso, a penalty proportional to the absolute value of the coefficients is added to the cost function. This tends to shrink some coefficients to exactly zero, making it useful for feature selection.\n",
    "\n",
    "The primary difference from other regression techniques, like **Ridge Regression**, is that Lasso can completely eliminate features by shrinking their coefficients to zero, whereas Ridge applies an L2 penalty and only reduces the size of coefficients, not eliminating them.\n",
    "\n",
    "---\n",
    "\n",
    "## Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\n",
    "The main advantage of using Lasso Regression for feature selection is that it can shrink the coefficients of less important features to exactly zero. This effectively removes these features from the model, allowing for simpler models with fewer features, which helps in avoiding overfitting and enhances interpretability.\n",
    "\n",
    "---\n",
    "\n",
    "## Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\n",
    "In a Lasso Regression model, the magnitude of the coefficients represents the relationship between the features and the target variable. Features with coefficients equal to zero have no influence on the target variable, meaning Lasso has selected them as unimportant. Non-zero coefficients indicate that the corresponding feature contributes to predicting the outcome.\n",
    "\n",
    "---\n",
    "\n",
    "## Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the model's performance?\n",
    "\n",
    "The primary tuning parameter in Lasso Regression is the **regularization parameter (lambda)**. It controls the strength of the L1 penalty. When lambda is set to zero, Lasso behaves like standard linear regression. As lambda increases, the coefficients shrink more, leading to simpler models with fewer features.\n",
    "\n",
    "- **Low lambda**: The model includes more features with larger coefficients.\n",
    "- **High lambda**: The model includes fewer features as more coefficients are shrunk to zero, improving feature selection but potentially underfitting the data.\n",
    "\n",
    "---\n",
    "\n",
    "## Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\n",
    "Yes, Lasso Regression can be used for non-linear problems, but not directly. To apply it to non-linear regression problems, you need to first transform the input features using techniques such as **polynomial features** or other basis function expansions. Once transformed, Lasso can be applied to the resulting higher-dimensional feature space.\n",
    "\n",
    "---\n",
    "\n",
    "## Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\n",
    "- **Penalty Type**: Lasso uses L1 regularization, which can shrink some coefficients to zero, effectively performing feature selection. Ridge uses L2 regularization, which shrinks coefficients but never to exactly zero, meaning all features are retained.\n",
    "- **Feature Selection**: Lasso can perform feature selection by eliminating less important features, while Ridge only shrinks their influence.\n",
    "- **Multicollinearity**: Both techniques address multicollinearity, but Lasso can simplify the model further by eliminating correlated features.\n",
    "\n",
    "---\n",
    "\n",
    "## Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\n",
    "Yes, Lasso Regression can handle multicollinearity by shrinking the coefficients of correlated features. It tends to select one feature from a group of highly correlated features and shrink the others to zero, thus reducing redundancy and improving model interpretability.\n",
    "\n",
    "---\n",
    "\n",
    "## Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\n",
    "The optimal value of the regularization parameter **lambda** is typically chosen using cross-validation. A common approach is to:\n",
    "\n",
    "1. **Divide the data** into training and validation sets.\n",
    "2. **Train the model** on the training set using different values of lambda.\n",
    "3. **Evaluate** the performance on the validation set.\n",
    "4. Choose the lambda that minimizes the validation error or maximizes the generalization ability of the model.\n",
    "5. Tools like **Grid Search** or **Randomized Search** can automate the process.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
