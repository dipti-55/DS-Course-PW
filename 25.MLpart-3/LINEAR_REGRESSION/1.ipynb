{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Questions - Regression 1\n",
    "\n",
    "## Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each.\n",
    "**Simple Linear Regression:** It is a type of regression where there is one dependent variable and one independent variable. The relationship between the two variables is represented by a straight line, i.e., `y = b0 + b1x`, where `y` is the dependent variable, `x` is the independent variable, `b0` is the intercept, and `b1` is the slope.\n",
    "\n",
    "*Example:* Predicting the weight of a person (dependent variable) based on their height (independent variable).\n",
    "\n",
    "**Multiple Linear Regression:** It is an extension of simple linear regression where there is one dependent variable and two or more independent variables. The equation becomes `y = b0 + b1x1 + b2x2 + ... + bnxn`.\n",
    "\n",
    "*Example:* Predicting the price of a house (dependent variable) based on its size, number of bedrooms, and location (independent variables).\n",
    "\n",
    "---\n",
    "\n",
    "## Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?\n",
    "1. **Linearity:** The relationship between the independent and dependent variable should be linear. You can check this using scatter plots.\n",
    "2. **Independence:** Observations should be independent of each other. This can be checked using the Durbin-Watson test.\n",
    "3. **Homoscedasticity:** The residuals (errors) should have constant variance. Residual plots can help verify this.\n",
    "4. **Normality:** The residuals should follow a normal distribution. This can be checked using a Q-Q plot or a Shapiro-Wilk test.\n",
    "5. **No Multicollinearity (for multiple linear regression):** Independent variables should not be highly correlated with each other. This can be checked using Variance Inflation Factor (VIF).\n",
    "\n",
    "---\n",
    "\n",
    "## Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario.\n",
    "In a linear regression model `y = b0 + b1x`:\n",
    "- **Slope (b1):** It represents the change in the dependent variable for each one-unit change in the independent variable. \n",
    "- **Intercept (b0):** It represents the value of the dependent variable when the independent variable is zero.\n",
    "\n",
    "*Example:* In a regression model predicting house prices based on size, if the slope is 300, it means for every additional square foot, the price increases by $300. If the intercept is 50,000, it means a house with 0 square feet would theoretically cost $50,000 (which might not make sense practically, but it's the intercept).\n",
    "\n",
    "---\n",
    "\n",
    "## Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "**Gradient Descent** is an optimization algorithm used to minimize the cost function (or error function) in machine learning models. It iteratively adjusts the model parameters (weights and biases) by calculating the gradient of the cost function with respect to the parameters and moving in the direction of the steepest descent (negative gradient) until the minimum error is reached.\n",
    "\n",
    "It is used in:\n",
    "- Training machine learning models such as linear regression, logistic regression, and neural networks.\n",
    "- Finding optimal parameters that reduce the prediction error.\n",
    "\n",
    "---\n",
    "\n",
    "## Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "**Multiple Linear Regression** is a model where there is one dependent variable and multiple independent variables. It can be expressed as:\n",
    "`y = b0 + b1x1 + b2x2 + ... + bnxn`, where `x1, x2, ..., xn` are the independent variables.\n",
    "\n",
    "**Difference:** Simple linear regression involves only one independent variable, while multiple linear regression involves two or more independent variables.\n",
    "\n",
    "---\n",
    "\n",
    "## Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?\n",
    "**Multicollinearity** occurs when two or more independent variables are highly correlated with each other, leading to difficulty in estimating the individual effect of each variable on the dependent variable.\n",
    "\n",
    "**Detection:**\n",
    "- High Variance Inflation Factor (VIF) values (greater than 10).\n",
    "- High correlation between independent variables (correlation coefficient close to 1 or -1).\n",
    "\n",
    "**Addressing Multicollinearity:**\n",
    "- Remove one of the correlated variables.\n",
    "- Combine the correlated variables into a single feature (e.g., through Principal Component Analysis).\n",
    "- Use regularization techniques like Ridge or Lasso regression.\n",
    "\n",
    "---\n",
    "\n",
    "## Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "**Polynomial Regression** is a type of regression where the relationship between the dependent and independent variables is modeled as an nth-degree polynomial. The equation is:\n",
    "`y = b0 + b1x + b2x^2 + ... + bnx^n`.\n",
    "\n",
    "**Difference:** While linear regression models a linear relationship between the variables, polynomial regression models a non-linear relationship using polynomial terms.\n",
    "\n",
    "---\n",
    "\n",
    "## Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?\n",
    "**Advantages of Polynomial Regression:**\n",
    "- Can model non-linear relationships between variables.\n",
    "- Provides a better fit for datasets where the relationship between variables is not linear.\n",
    "\n",
    "**Disadvantages of Polynomial Regression:**\n",
    "- Can lead to overfitting, especially with high-degree polynomials.\n",
    "- More complex and harder to interpret than linear regression.\n",
    "\n",
    "**When to Use Polynomial Regression:**\n",
    "- When the relationship between the independent and dependent variables is non-linear.\n",
    "- When adding polynomial terms significantly improves model performance without overfitting.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
